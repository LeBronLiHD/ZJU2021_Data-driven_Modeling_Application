{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  1594.000000  1594.000000  1594.000000  1594.000000  1594.000000   \nmean      0.267529     0.666682     0.579779     0.478029     0.692702   \nstd       0.094432     0.037008     0.212320     0.115477     0.101770   \nmin       0.008426     0.557551     0.001440     0.165742     0.096200   \n25%       0.216349     0.647840     0.455951     0.376192     0.666228   \n50%       0.247845     0.665151     0.621989     0.476177     0.712947   \n75%       0.295859     0.683507     0.726308     0.551909     0.742075   \nmax       0.812926     1.381089     1.349245     0.976177     1.227174   \n\n                5            6            7            8            9   ...  \\\ncount  1594.000000  1594.000000  1594.000000  1594.000000  1594.000000  ...   \nmean      0.678323     0.650067     0.267395     0.666722     0.579776  ...   \nstd       0.153000     0.165280     0.094583     0.037025     0.212316  ...   \nmin       0.115021     0.078406     0.008426     0.557551     0.001440  ...   \n25%       0.564865     0.527276     0.216291     0.647840     0.455951  ...   \n50%       0.721453     0.694735     0.247621     0.665164     0.621989  ...   \n75%       0.791142     0.774919     0.295859     0.683533     0.726308  ...   \nmax       1.203539     1.399412     0.812926     1.381089     1.349245  ...   \n\n                11           12           13           14           15  \\\ncount  1594.000000  1594.000000  1594.000000  1594.000000  1594.000000   \nmean      0.692242     0.677902     0.649638     0.267259     0.666757   \nstd       0.103002     0.153467     0.165722     0.094736     0.037036   \nmin       0.051885     0.115021     0.078406     0.008426     0.557551   \n25%       0.666160     0.563898     0.527149     0.216174     0.647840   \n50%       0.712823     0.721214     0.694653     0.247558     0.665187   \n75%       0.741999     0.790996     0.774756     0.295859     0.683630   \nmax       1.227174     1.203539     1.399412     0.812926     1.381089   \n\n                16           17           18           19           20  \ncount  1594.000000  1594.000000  1594.000000  1594.000000  1594.000000  \nmean      0.579759     0.477747     0.692009     0.677456     0.649182  \nstd       0.212294     0.115502     0.103232     0.154033     0.166244  \nmin       0.001440     0.165742     0.051885     0.115021     0.078406  \n25%       0.455951     0.376144     0.666011     0.563395     0.527134  \n50%       0.621989     0.475943     0.712736     0.720956     0.694551  \n75%       0.726308     0.551635     0.741900     0.790799     0.774544  \nmax       1.349245     0.976177     1.227174     1.203539     1.399412  \n\n[8 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>...</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n      <td>1594.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.267529</td>\n      <td>0.666682</td>\n      <td>0.579779</td>\n      <td>0.478029</td>\n      <td>0.692702</td>\n      <td>0.678323</td>\n      <td>0.650067</td>\n      <td>0.267395</td>\n      <td>0.666722</td>\n      <td>0.579776</td>\n      <td>...</td>\n      <td>0.692242</td>\n      <td>0.677902</td>\n      <td>0.649638</td>\n      <td>0.267259</td>\n      <td>0.666757</td>\n      <td>0.579759</td>\n      <td>0.477747</td>\n      <td>0.692009</td>\n      <td>0.677456</td>\n      <td>0.649182</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.094432</td>\n      <td>0.037008</td>\n      <td>0.212320</td>\n      <td>0.115477</td>\n      <td>0.101770</td>\n      <td>0.153000</td>\n      <td>0.165280</td>\n      <td>0.094583</td>\n      <td>0.037025</td>\n      <td>0.212316</td>\n      <td>...</td>\n      <td>0.103002</td>\n      <td>0.153467</td>\n      <td>0.165722</td>\n      <td>0.094736</td>\n      <td>0.037036</td>\n      <td>0.212294</td>\n      <td>0.115502</td>\n      <td>0.103232</td>\n      <td>0.154033</td>\n      <td>0.166244</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.008426</td>\n      <td>0.557551</td>\n      <td>0.001440</td>\n      <td>0.165742</td>\n      <td>0.096200</td>\n      <td>0.115021</td>\n      <td>0.078406</td>\n      <td>0.008426</td>\n      <td>0.557551</td>\n      <td>0.001440</td>\n      <td>...</td>\n      <td>0.051885</td>\n      <td>0.115021</td>\n      <td>0.078406</td>\n      <td>0.008426</td>\n      <td>0.557551</td>\n      <td>0.001440</td>\n      <td>0.165742</td>\n      <td>0.051885</td>\n      <td>0.115021</td>\n      <td>0.078406</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.216349</td>\n      <td>0.647840</td>\n      <td>0.455951</td>\n      <td>0.376192</td>\n      <td>0.666228</td>\n      <td>0.564865</td>\n      <td>0.527276</td>\n      <td>0.216291</td>\n      <td>0.647840</td>\n      <td>0.455951</td>\n      <td>...</td>\n      <td>0.666160</td>\n      <td>0.563898</td>\n      <td>0.527149</td>\n      <td>0.216174</td>\n      <td>0.647840</td>\n      <td>0.455951</td>\n      <td>0.376144</td>\n      <td>0.666011</td>\n      <td>0.563395</td>\n      <td>0.527134</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.247845</td>\n      <td>0.665151</td>\n      <td>0.621989</td>\n      <td>0.476177</td>\n      <td>0.712947</td>\n      <td>0.721453</td>\n      <td>0.694735</td>\n      <td>0.247621</td>\n      <td>0.665164</td>\n      <td>0.621989</td>\n      <td>...</td>\n      <td>0.712823</td>\n      <td>0.721214</td>\n      <td>0.694653</td>\n      <td>0.247558</td>\n      <td>0.665187</td>\n      <td>0.621989</td>\n      <td>0.475943</td>\n      <td>0.712736</td>\n      <td>0.720956</td>\n      <td>0.694551</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.295859</td>\n      <td>0.683507</td>\n      <td>0.726308</td>\n      <td>0.551909</td>\n      <td>0.742075</td>\n      <td>0.791142</td>\n      <td>0.774919</td>\n      <td>0.295859</td>\n      <td>0.683533</td>\n      <td>0.726308</td>\n      <td>...</td>\n      <td>0.741999</td>\n      <td>0.790996</td>\n      <td>0.774756</td>\n      <td>0.295859</td>\n      <td>0.683630</td>\n      <td>0.726308</td>\n      <td>0.551635</td>\n      <td>0.741900</td>\n      <td>0.790799</td>\n      <td>0.774544</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.812926</td>\n      <td>1.381089</td>\n      <td>1.349245</td>\n      <td>0.976177</td>\n      <td>1.227174</td>\n      <td>1.203539</td>\n      <td>1.399412</td>\n      <td>0.812926</td>\n      <td>1.381089</td>\n      <td>1.349245</td>\n      <td>...</td>\n      <td>1.227174</td>\n      <td>1.203539</td>\n      <td>1.399412</td>\n      <td>0.812926</td>\n      <td>1.381089</td>\n      <td>1.349245</td>\n      <td>0.976177</td>\n      <td>1.227174</td>\n      <td>1.203539</td>\n      <td>1.399412</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_input=np.loadtxt('train_modify.txt',dtype=np.float32)\n",
    "output=np.loadtxt('output_modify.txt',dtype=np.float32)\n",
    "data_train=pd.DataFrame(train_input)\n",
    "data_output=pd.DataFrame(output)\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                 0\ncount  1594.000000\nmean      0.258198\nstd       0.137596\nmin       0.019020\n25%       0.178365\n50%       0.245083\n75%       0.297560\nmax       1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1594.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.258198</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.137596</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.019020</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.178365</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.245083</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.297560</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "               0           1           2           3           4           5   \\\ncount  798.000000  798.000000  798.000000  798.000000  798.000000  798.000000   \nmean     0.316946    0.671740    0.636060    0.352182    0.590489    0.506054   \nstd      0.111345    0.090890    0.163141    0.142608    0.143834    0.123694   \nmin      0.040359    0.031766    0.174480    0.000282    0.001254    0.015904   \n25%      0.258151    0.667573    0.545045    0.357026    0.531429    0.431870   \n50%      0.305178    0.686002    0.625497    0.364650    0.619565    0.493386   \n75%      0.360525    0.702930    0.749993    0.375342    0.690893    0.570393   \nmax      1.001941    0.782632    0.965611    1.133764    0.897153    0.926988   \n\n               6           7           8           9   ...          11  \\\ncount  798.000000  798.000000  798.000000  798.000000  ...  798.000000   \nmean     0.468946    0.317164    0.671688    0.635871  ...    0.591089   \nstd      0.119104    0.111000    0.090877    0.163006  ...    0.142578   \nmin      0.010062    0.040359    0.031766    0.174480  ...    0.001254   \n25%      0.395685    0.258151    0.667573    0.545045  ...    0.531429   \n50%      0.466630    0.305178    0.685874    0.625497  ...    0.619565   \n75%      0.534970    0.360525    0.702903    0.749723  ...    0.690893   \nmax      0.851098    1.001941    0.782632    0.965611  ...    0.897153   \n\n               12          13          14          15          16          17  \\\ncount  798.000000  798.000000  798.000000  798.000000  798.000000  798.000000   \nmean     0.506635    0.469447    0.317369    0.671641    0.635688    0.352175   \nstd      0.123216    0.118547    0.110661    0.090869    0.162876    0.142608   \nmin      0.015904    0.010062    0.040359    0.031766    0.174480    0.000282   \n25%      0.432251    0.395936    0.258151    0.667573    0.545045    0.357026   \n50%      0.493518    0.466768    0.305178    0.685803    0.625497    0.364650   \n75%      0.570766    0.535480    0.360525    0.702688    0.749335    0.375342   \nmax      0.926988    0.851098    1.001941    0.782632    0.965611    1.133764   \n\n               18          19          20  \ncount  798.000000  798.000000  798.000000  \nmean     0.591209    0.507335    0.470041  \nstd      0.142461    0.122640    0.117860  \nmin      0.001254    0.015904    0.010062  \n25%      0.531429    0.432439    0.396137  \n50%      0.619565    0.493633    0.466793  \n75%      0.690893    0.570895    0.535680  \nmax      0.897153    0.926988    0.851098  \n\n[8 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>...</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n      <td>798.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.316946</td>\n      <td>0.671740</td>\n      <td>0.636060</td>\n      <td>0.352182</td>\n      <td>0.590489</td>\n      <td>0.506054</td>\n      <td>0.468946</td>\n      <td>0.317164</td>\n      <td>0.671688</td>\n      <td>0.635871</td>\n      <td>...</td>\n      <td>0.591089</td>\n      <td>0.506635</td>\n      <td>0.469447</td>\n      <td>0.317369</td>\n      <td>0.671641</td>\n      <td>0.635688</td>\n      <td>0.352175</td>\n      <td>0.591209</td>\n      <td>0.507335</td>\n      <td>0.470041</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.111345</td>\n      <td>0.090890</td>\n      <td>0.163141</td>\n      <td>0.142608</td>\n      <td>0.143834</td>\n      <td>0.123694</td>\n      <td>0.119104</td>\n      <td>0.111000</td>\n      <td>0.090877</td>\n      <td>0.163006</td>\n      <td>...</td>\n      <td>0.142578</td>\n      <td>0.123216</td>\n      <td>0.118547</td>\n      <td>0.110661</td>\n      <td>0.090869</td>\n      <td>0.162876</td>\n      <td>0.142608</td>\n      <td>0.142461</td>\n      <td>0.122640</td>\n      <td>0.117860</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.040359</td>\n      <td>0.031766</td>\n      <td>0.174480</td>\n      <td>0.000282</td>\n      <td>0.001254</td>\n      <td>0.015904</td>\n      <td>0.010062</td>\n      <td>0.040359</td>\n      <td>0.031766</td>\n      <td>0.174480</td>\n      <td>...</td>\n      <td>0.001254</td>\n      <td>0.015904</td>\n      <td>0.010062</td>\n      <td>0.040359</td>\n      <td>0.031766</td>\n      <td>0.174480</td>\n      <td>0.000282</td>\n      <td>0.001254</td>\n      <td>0.015904</td>\n      <td>0.010062</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.258151</td>\n      <td>0.667573</td>\n      <td>0.545045</td>\n      <td>0.357026</td>\n      <td>0.531429</td>\n      <td>0.431870</td>\n      <td>0.395685</td>\n      <td>0.258151</td>\n      <td>0.667573</td>\n      <td>0.545045</td>\n      <td>...</td>\n      <td>0.531429</td>\n      <td>0.432251</td>\n      <td>0.395936</td>\n      <td>0.258151</td>\n      <td>0.667573</td>\n      <td>0.545045</td>\n      <td>0.357026</td>\n      <td>0.531429</td>\n      <td>0.432439</td>\n      <td>0.396137</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.305178</td>\n      <td>0.686002</td>\n      <td>0.625497</td>\n      <td>0.364650</td>\n      <td>0.619565</td>\n      <td>0.493386</td>\n      <td>0.466630</td>\n      <td>0.305178</td>\n      <td>0.685874</td>\n      <td>0.625497</td>\n      <td>...</td>\n      <td>0.619565</td>\n      <td>0.493518</td>\n      <td>0.466768</td>\n      <td>0.305178</td>\n      <td>0.685803</td>\n      <td>0.625497</td>\n      <td>0.364650</td>\n      <td>0.619565</td>\n      <td>0.493633</td>\n      <td>0.466793</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.360525</td>\n      <td>0.702930</td>\n      <td>0.749993</td>\n      <td>0.375342</td>\n      <td>0.690893</td>\n      <td>0.570393</td>\n      <td>0.534970</td>\n      <td>0.360525</td>\n      <td>0.702903</td>\n      <td>0.749723</td>\n      <td>...</td>\n      <td>0.690893</td>\n      <td>0.570766</td>\n      <td>0.535480</td>\n      <td>0.360525</td>\n      <td>0.702688</td>\n      <td>0.749335</td>\n      <td>0.375342</td>\n      <td>0.690893</td>\n      <td>0.570895</td>\n      <td>0.535680</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.001941</td>\n      <td>0.782632</td>\n      <td>0.965611</td>\n      <td>1.133764</td>\n      <td>0.897153</td>\n      <td>0.926988</td>\n      <td>0.851098</td>\n      <td>1.001941</td>\n      <td>0.782632</td>\n      <td>0.965611</td>\n      <td>...</td>\n      <td>0.897153</td>\n      <td>0.926988</td>\n      <td>0.851098</td>\n      <td>1.001941</td>\n      <td>0.782632</td>\n      <td>0.965611</td>\n      <td>1.133764</td>\n      <td>0.897153</td>\n      <td>0.926988</td>\n      <td>0.851098</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input=np.loadtxt('test_modify.txt',dtype=np.float32)\n",
    "data_test=pd.DataFrame(test_input)\n",
    "data_test.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     交叉验证的划分\n",
    "# \"\"\"\n",
    "#\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# #data_train(全部数据) output(全部目标值)\n",
    "# #X_train训练集(全部特征) Y_train训练集的目标值\n",
    "# #test同理。\n",
    "# # 这里没有设置random\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(data_train,output, test_size=0.2,shuffle=False) #这里训练集75%:测试集25%\n",
    "# import numpy as np\n",
    "# from sklearn import ensemble\n",
    "# random_forest_regressor = ensemble.RandomForestRegressor(n_estimators=100,criterion=\"squared_error\")\n",
    "# RF1 = random_forest_regressor.fit(X_train, Y_train)\n",
    "#\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# Y_train_pred = RF1.predict(X_train)\n",
    "#\n",
    "# Y_test_pred = RF1.predict(X_test)\n",
    "# Y_test = np.array(Y_test)\n",
    "# print(mean_squared_error(Y_train,Y_train_pred))\n",
    "# # 拟合\n",
    "# print(mean_squared_error(Y_test,Y_test_pred))\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig1, ax1 = plt.subplots(figsize=(8,6))\n",
    "# ax1.plot(Y_train_pred, '--', label='RF1')\n",
    "# ax1.plot(Y_train, '-',label='Y_train')\n",
    "# ax1.legend(loc='best')\n",
    "#\n",
    "# fig2, ax2 = plt.subplots(figsize=(8,6))\n",
    "# ax2.plot(Y_test_pred, '--',label='RF1')\n",
    "# ax2.plot(Y_test, '-', label='Y_test')\n",
    "# ax2.legend(loc='best')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn import ensemble\n",
    "# # random_forest_regressor = \\\n",
    "# #     ensemble.RandomForestRegressor(n_estimators=100,\n",
    "# #                                    criterion=\"squared_error\")\n",
    "# # RF = random_forest_regressor.fit(data_train,data_output)\n",
    "# RF = ensemble.RandomForestRegressor(n_estimators=100,random_state=90)\n",
    "# score_pre = cross_val_score(RF, data_train, data_output, cv=10).mean()\n",
    "# score_pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# score_lt = []\n",
    "# import matplotlib.pyplot as plt\n",
    "# # 每隔10步建立一个随机森林，获得不同n_estimators的得分\n",
    "# for i in range(0,200,10):\n",
    "#     RF = ensemble.RandomForestRegressor(n_estimators=i+1,random_state=90)\n",
    "#     score = cross_val_score(RF, data_train, data_output, cv=10).mean()\n",
    "#     score_lt.append(score)\n",
    "# score_max = max(score_lt)\n",
    "# print('最大得分：{}'.format(score_max),\n",
    "#       '子树数量为：{}'.format(score_lt.index(score_max)*10+1))\n",
    "#\n",
    "# # 绘制学习曲线\n",
    "# x = np.arange(1,201,10)\n",
    "# plt.subplot(111)\n",
    "# plt.plot(x, score_lt, 'r-')\n",
    "# plt.show()\n",
    "# #140个树左右\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# #140个树左右\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn import ensemble\n",
    "# import matplotlib.pyplot as plt\n",
    "# score_lt = []\n",
    "# import matplotlib.pyplot as plt\n",
    "# # 每隔10步建立一个随机森林，获得不同n_estimators的得分\n",
    "# for i in range(130,150):\n",
    "#     RF = ensemble.RandomForestRegressor(n_estimators=i,random_state=90)\n",
    "#     score = cross_val_score(RF, data_train, data_output, cv=10).mean()\n",
    "#     score_lt.append(score)\n",
    "# score_max = max(score_lt)\n",
    "# print('最大得分：{}'.format(score_max),\n",
    "#       '子树数量为：{}'.format(score_lt.index(score_max)+130))\n",
    "#\n",
    "# # 绘制学习曲线\n",
    "# x = np.arange(130,150)\n",
    "# plt.subplot(111)\n",
    "# plt.plot(x, score_lt, 'o-')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn import ensemble\n",
    "# # 建立n_estimators为139的随机森林\n",
    "# RF = ensemble.RandomForestRegressor(n_estimators=139,random_state=90)\n",
    "#\n",
    "# # 用网格搜索调整max_depth\n",
    "# param_grid = {'max_depth':np.arange(1,20)}\n",
    "# GS = GridSearchCV(RF, param_grid, cv=10)\n",
    "# GS.fit(data_train, data_output)\n",
    "#\n",
    "# best_param = GS.best_params_\n",
    "# best_score = GS.best_score_\n",
    "# print(best_param, best_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# #max_depth = 2，认真的吗？,树个数139，调整max_features\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn import ensemble\n",
    "# param_grid = {'max_features':np.arange(5,21)}\n",
    "#\n",
    "# RF = ensemble.RandomForestRegressor(n_estimators=139\n",
    "#                             ,random_state=90)\n",
    "# GS = GridSearchCV(RF, param_grid, cv=10)\n",
    "# GS.fit(data_train, data_output)\n",
    "# best_param = GS.best_params_\n",
    "# best_score = GS.best_score_\n",
    "# print(best_param, best_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_8912/885394801.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  RFF = RF.fit(data_train,data_output)\n"
     ]
    }
   ],
   "source": [
    "#max_depth默认好了，树个数139，max_features = 16或者6\n",
    "from sklearn import ensemble\n",
    "RF = ensemble.RandomForestRegressor(n_estimators=139\n",
    "                            ,random_state=90,max_features=16)\n",
    "RFF = RF.fit(data_train,data_output)\n",
    "y_test = RFF.predict(data_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.index = np.linspace(1,798,798)\n",
    "y_test.to_csv(\"test_RF.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}